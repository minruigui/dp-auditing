{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "652/652 [==============================] - 5s 2ms/step - loss: 2902.1064 - accuracy: 0.7155 - val_loss: 5608.8682 - val_accuracy: 0.7524\n",
      "Epoch 2/10\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 8274.3506 - accuracy: 0.7766 - val_loss: 11686.6865 - val_accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 18941.4316 - accuracy: 0.7907 - val_loss: 24367.3535 - val_accuracy: 0.7833\n",
      "Epoch 4/10\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 26538.1875 - accuracy: 0.7858 - val_loss: 35900.9961 - val_accuracy: 0.7418\n",
      "Epoch 5/10\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 40310.9531 - accuracy: 0.7656 - val_loss: 51451.5977 - val_accuracy: 0.7649\n",
      "Epoch 6/10\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 50473.9375 - accuracy: 0.7636 - val_loss: 51483.4180 - val_accuracy: 0.7568\n",
      "Epoch 7/10\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 45500.3672 - accuracy: 0.7888 - val_loss: 46324.9727 - val_accuracy: 0.7948\n",
      "Epoch 8/10\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 57475.7148 - accuracy: 0.7946 - val_loss: 67229.8906 - val_accuracy: 0.7904\n",
      "Epoch 9/10\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 77336.5625 - accuracy: 0.7981 - val_loss: 82496.1562 - val_accuracy: 0.8090\n",
      "Epoch 10/10\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 84566.9453 - accuracy: 0.8142 - val_loss: 84648.1172 - val_accuracy: 0.7998\n",
      "204/204 [==============================] - 0s 961us/step - loss: 83593.3281 - accuracy: 0.8115\n",
      "Test Accuracy: 81.15%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow_privacy\n",
    "\n",
    "# Load dataset\n",
    "url = \"~/Downloads/adult.csv\"\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "                'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "data = pd.read_csv(url, names=column_names, sep=r'\\s*,\\s*', engine='python')\n",
    "\n",
    "# Preprocess data\n",
    "X = data.drop('income', axis=1)\n",
    "y = data['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "y = np.eye(2)[y]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define preprocessor\n",
    "numeric_features = ['age', 'fnlwgt', 'education-num',\n",
    "                    'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "categorical_features = ['workclass', 'education', 'marital-status',\n",
    "                        'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train).toarray()\n",
    "X_test = pipeline.transform(X_test).toarray()\n",
    "\n",
    "# Define model\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(64, activation='relu',\n",
    "#                           input_shape=(X_train.shape[1],)),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu',\n",
    "                          kernel_initializer='glorot_normal', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, kernel_initializer='glorot_normal',activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tensorflow_privacy.VectorizedDPKerasSGDOptimizer(\n",
    "    l2_norm_clip=1,\n",
    "    noise_multiplier=2.0,\n",
    "    num_microbatches=1,\n",
    "    learning_rate=0.15)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05707762557077625, 8.449847843680425)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def e_th():\n",
    "    import math\n",
    "    # Given parameters\n",
    "    D_size = 6000\n",
    "    b = 250\n",
    "    epochs = 24\n",
    "    C = 1\n",
    "    sigma = 0.73\n",
    "    delta = 1e-8\n",
    "\n",
    "    # Compute q, the sampling ratio\n",
    "    q = b / D_size\n",
    "\n",
    "    # Compute Delta f (sensitivity of the function)\n",
    "    Delta_f = C\n",
    "\n",
    "    # Compute epsilon for each step\n",
    "    epsilon_per_step = q * Delta_f / sigma\n",
    "\n",
    "    # Compute the number of steps T across all epochs\n",
    "    T = (D_size / b) * epochs\n",
    "\n",
    "    # Compute epsilon_total using advanced composition theorem\n",
    "    epsilon_total = math.sqrt(2 * T * math.log(1/delta)) * \\\n",
    "    epsilon_per_step + T * epsilon_per_step**2\n",
    "\n",
    "    return epsilon_per_step, epsilon_total\n",
    "\n",
    "\n",
    "e_th()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
