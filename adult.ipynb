{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "652/652 [==============================] - 5s 2ms/step - loss: 847.0057 - accuracy: 0.5683 - val_loss: 2423.0217 - val_accuracy: 0.4894\n",
      "Epoch 2/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 2778.5403 - accuracy: 0.6169 - val_loss: 5092.7314 - val_accuracy: 0.5077\n",
      "Epoch 3/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 5723.6484 - accuracy: 0.5726 - val_loss: 8462.6357 - val_accuracy: 0.5818\n",
      "Epoch 4/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 8407.7773 - accuracy: 0.6818 - val_loss: 10234.6514 - val_accuracy: 0.7430\n",
      "Epoch 5/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 11762.8018 - accuracy: 0.6496 - val_loss: 13779.1260 - val_accuracy: 0.6601\n",
      "Epoch 6/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 17667.5742 - accuracy: 0.6092 - val_loss: 17710.5469 - val_accuracy: 0.6985\n",
      "Epoch 7/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 19364.3477 - accuracy: 0.7046 - val_loss: 20184.2109 - val_accuracy: 0.7081\n",
      "Epoch 8/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 22647.0020 - accuracy: 0.7078 - val_loss: 29475.4492 - val_accuracy: 0.7044\n",
      "Epoch 9/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 34705.2930 - accuracy: 0.7235 - val_loss: 34094.5508 - val_accuracy: 0.7399\n",
      "Epoch 10/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 38180.2070 - accuracy: 0.7286 - val_loss: 42066.0430 - val_accuracy: 0.7326\n",
      "Epoch 11/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 44013.3281 - accuracy: 0.7350 - val_loss: 38399.9141 - val_accuracy: 0.7244\n",
      "Epoch 12/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 40087.6094 - accuracy: 0.6739 - val_loss: 46709.2422 - val_accuracy: 0.6273\n",
      "Epoch 13/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 48043.4844 - accuracy: 0.7020 - val_loss: 51132.9688 - val_accuracy: 0.7608\n",
      "Epoch 14/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 69430.3281 - accuracy: 0.7592 - val_loss: 74794.0859 - val_accuracy: 0.7597\n",
      "Epoch 15/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 79108.9375 - accuracy: 0.7592 - val_loss: 84816.6250 - val_accuracy: 0.7610\n",
      "Epoch 16/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 87098.1641 - accuracy: 0.7522 - val_loss: 82174.9531 - val_accuracy: 0.7428\n",
      "Epoch 17/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 85416.8828 - accuracy: 0.7421 - val_loss: 80231.1484 - val_accuracy: 0.7202\n",
      "Epoch 18/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 73218.5703 - accuracy: 0.7307 - val_loss: 63445.4375 - val_accuracy: 0.7468\n",
      "Epoch 19/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 64732.9570 - accuracy: 0.7406 - val_loss: 67669.8594 - val_accuracy: 0.7296\n",
      "Epoch 20/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 70206.3516 - accuracy: 0.7248 - val_loss: 80316.5312 - val_accuracy: 0.7463\n",
      "204/204 [==============================] - 0s 974us/step - loss: 83897.1094 - accuracy: 0.7356\n",
      "Test Accuracy: 73.56%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow_privacy\n",
    "\n",
    "# Load dataset\n",
    "url = \"~/Downloads/adult.csv\"\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "                'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "data = pd.read_csv(url, names=column_names, sep=r'\\s*,\\s*', engine='python')\n",
    "\n",
    "# Preprocess data\n",
    "X = data.drop('income', axis=1)\n",
    "y = data['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "y = np.eye(2)[y]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define preprocessor\n",
    "numeric_features = ['age', 'fnlwgt', 'education-num',\n",
    "                    'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "categorical_features = ['workclass', 'education', 'marital-status',\n",
    "                        'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train).toarray()\n",
    "X_test = pipeline.transform(X_test).toarray()\n",
    "\n",
    "# Define model\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(64, activation='relu',\n",
    "#                           input_shape=(X_train.shape[1],)),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu',\n",
    "                          kernel_initializer='glorot_normal', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, kernel_initializer='glorot_normal',activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tensorflow_privacy.VectorizedDPKerasSGDOptimizer(\n",
    "    l2_norm_clip=1,\n",
    "    noise_multiplier=100.0,\n",
    "    num_microbatches=1,\n",
    "    learning_rate=0.15)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05707762557077625, 11.172607449470878)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def e_th():\n",
    "    import math\n",
    "    # Given parameters\n",
    "    D_size = 6000\n",
    "    b = 250\n",
    "    epochs = 24\n",
    "    C = 1\n",
    "    sigma = 0.73\n",
    "    delta = 1e-5\n",
    "    # Compute q, the sampling ratio\n",
    "    q = b / D_size\n",
    "    # Compute Delta f (sensitivity of the function)\n",
    "    Delta_f = C\n",
    "    # Compute epsilon for each step\n",
    "    epsilon_per_step = q * Delta_f / sigma\n",
    "    # Compute the number of steps T across all epochs\n",
    "    T = (D_size / b) * epochs\n",
    "    # Compute epsilon_total using advanced composition theorem\n",
    "    epsilon_total = math.sqrt(2 * T * math.log(1/delta)) * \\\n",
    "    epsilon_per_step + T * epsilon_per_step**2\n",
    "\n",
    "    return epsilon_per_step, epsilon_total\n",
    "\n",
    "\n",
    "e_th()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occupation            ?   Adm-clerical   Armed-Forces   Craft-repair  \\\n",
      "education                                                              \n",
      " 10th          0.003133       0.001167       0.000000       0.005221   \n",
      " 11th          0.003655       0.002058       0.000000       0.005375   \n",
      " 12th          0.001228       0.001167       0.000031       0.001781   \n",
      " 1st-4th       0.000369       0.000000       0.000000       0.000706   \n",
      " 5th-6th       0.000921       0.000184       0.000000       0.001321   \n",
      " 7th-8th       0.002242       0.000338       0.000000       0.003563   \n",
      " 9th           0.001566       0.000430       0.000000       0.002948   \n",
      " Assoc-acdm    0.001443       0.005927       0.000000       0.003532   \n",
      " Assoc-voc     0.001873       0.005129       0.000000       0.007739   \n",
      " Bachelors     0.005313       0.015540       0.000031       0.006941   \n",
      " Doctorate     0.000461       0.000154       0.000000       0.000061   \n",
      " HS-grad       0.016369       0.041921       0.000123       0.059028   \n",
      " Masters       0.001474       0.002088       0.000031       0.000676   \n",
      " Preschool     0.000154       0.000061       0.000000       0.000123   \n",
      " Prof-school   0.000553       0.000276       0.000000       0.000215   \n",
      " Some-college  0.015847       0.039342       0.000061       0.026658   \n",
      "\n",
      "occupation      Exec-managerial   Farming-fishing   Handlers-cleaners  \\\n",
      "education                                                               \n",
      " 10th                  0.000737          0.001351            0.002181   \n",
      " 11th                  0.001044          0.001136            0.003778   \n",
      " 12th                  0.000399          0.000491            0.001167   \n",
      " 1st-4th               0.000123          0.000553            0.000491   \n",
      " 5th-6th               0.000031          0.001106            0.001228   \n",
      " 7th-8th               0.000584          0.002150            0.001413   \n",
      " 9th                   0.000399          0.000860            0.001505   \n",
      " Assoc-acdm            0.004453          0.000430            0.000737   \n",
      " Assoc-voc             0.004607          0.001597            0.000860   \n",
      " Bachelors             0.042044          0.002365            0.001536   \n",
      " Doctorate             0.001689          0.000031            0.000000   \n",
      " HS-grad               0.024784          0.012407            0.018765   \n",
      " Masters               0.015387          0.000307            0.000154   \n",
      " Preschool             0.000000          0.000276            0.000061   \n",
      " Prof-school           0.001597          0.000123            0.000000   \n",
      " Some-college          0.026995          0.005344            0.008200   \n",
      "\n",
      "occupation      Machine-op-inspct   Other-service   Priv-house-serv  \\\n",
      "education                                                             \n",
      " 10th                    0.003102        0.005958          0.000184   \n",
      " 11th                    0.003040        0.007309          0.000430   \n",
      " 12th                    0.001075        0.002610          0.000123   \n",
      " 1st-4th                 0.000706        0.001228          0.000338   \n",
      " 5th-6th                 0.001720        0.001966          0.000430   \n",
      " 7th-8th                 0.002856        0.003010          0.000246   \n",
      " 9th                     0.002334        0.003102          0.000307   \n",
      " Assoc-acdm              0.001013        0.002396          0.000061   \n",
      " Assoc-voc               0.001935        0.003532          0.000123   \n",
      " Bachelors               0.002119        0.005559          0.000215   \n",
      " Doctorate               0.000031        0.000031          0.000000   \n",
      " HS-grad                 0.031418        0.039342          0.001536   \n",
      " Masters                 0.000246        0.000584          0.000031   \n",
      " Preschool               0.000338        0.000461          0.000061   \n",
      " Prof-school             0.000031        0.000123          0.000000   \n",
      " Some-college            0.009521        0.023986          0.000491   \n",
      "\n",
      "occupation      Prof-specialty   Protective-serv     Sales   Tech-support  \\\n",
      "education                                                                   \n",
      " 10th                 0.000276          0.000184  0.002488       0.000092   \n",
      " 11th                 0.000614          0.000215  0.004422       0.000184   \n",
      " 12th                 0.000307          0.000184  0.001443       0.000092   \n",
      " 1st-4th              0.000123          0.000031  0.000246       0.000000   \n",
      " 5th-6th              0.000031          0.000031  0.000369       0.000031   \n",
      " 7th-8th              0.000276          0.000276  0.000891       0.000154   \n",
      " 9th                  0.000092          0.000123  0.000983       0.000061   \n",
      " Assoc-acdm           0.004238          0.001044  0.004422       0.002242   \n",
      " Assoc-voc            0.005221          0.001474  0.003255       0.003870   \n",
      " Bachelors            0.045914          0.003071  0.024846       0.007064   \n",
      " Doctorate            0.009858          0.000000  0.000246       0.000092   \n",
      " HS-grad              0.007156          0.006603  0.032831       0.004883   \n",
      " Masters              0.025921          0.000461  0.004115       0.001136   \n",
      " Preschool            0.000031          0.000000  0.000000       0.000000   \n",
      " Prof-school          0.013882          0.000031  0.000553       0.000215   \n",
      " Some-college         0.013206          0.006204  0.030988       0.008384   \n",
      "\n",
      "occupation      Transport-moving  \n",
      "education                         \n",
      " 10th                   0.002580  \n",
      " 11th                   0.002825  \n",
      " 12th                   0.001198  \n",
      " 1st-4th                0.000246  \n",
      " 5th-6th                0.000860  \n",
      " 7th-8th                0.001843  \n",
      " 9th                    0.001075  \n",
      " Assoc-acdm             0.000829  \n",
      " Assoc-voc              0.001228  \n",
      " Bachelors              0.001904  \n",
      " Doctorate              0.000031  \n",
      " HS-grad                0.025337  \n",
      " Masters                0.000307  \n",
      " Preschool              0.000000  \n",
      " Prof-school            0.000092  \n",
      " Some-college           0.008691  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def calculate_combination_probabilities(data, feature1, feature2):\n",
    "    \"\"\"\n",
    "    Calculate the probabilities of all combinations of two feature values in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame containing the dataset\n",
    "    - feature1: Name of the first feature\n",
    "    - feature2: Name of the second feature\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing probabilities of each combination\n",
    "    \"\"\"\n",
    "    # Create a pivot table with counts of each combination\n",
    "    pivot_table = data.groupby(\n",
    "        [feature1, feature2]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    total_rows = len(data)\n",
    "    probability_table = pivot_table / total_rows\n",
    "\n",
    "    return probability_table\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('adult.csv', header=None, names=[\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"native-country\", \"income\"\n",
    "])\n",
    "\n",
    "# Calculate the probabilities for the combination of 'education' and 'occupation'\n",
    "probability_table = calculate_combination_probabilities(\n",
    "    data, 'education', 'occupation')\n",
    "print(probability_table)\n",
    "\n",
    "# If you want to save this table to a CSV file:\n",
    "# probability_table.to_csv('feature_combination_probabilities.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education      occupation       \n",
       " 10th           ?                    102\n",
       "                Adm-clerical          38\n",
       "                Craft-repair         170\n",
       "                Exec-managerial       24\n",
       "                Farming-fishing       44\n",
       "                                    ... \n",
       " Some-college   Prof-specialty       430\n",
       "                Protective-serv      202\n",
       "                Sales               1009\n",
       "                Tech-support         273\n",
       "                Transport-moving     283\n",
       "Length: 217, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['education', 'occupation']).size()\n",
    "[-0.001,1.0003]\n",
    "[1,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
